{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83380356-b07f-4370-83ba-18dfc99d0aeb",
   "metadata": {},
   "source": [
    "**Question 1: Running Elastic**\n",
    "____\n",
    "Run Elastic Search 8.17.6, and get the cluster information. If you run it on localhost, this is how you do it:\n",
    "```shell\n",
    "curl localhost:9200\n",
    "```\n",
    "What's the `version.build_hash` value?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7bd255-f67c-4dab-bcbd-dd117f1a06da",
   "metadata": {},
   "source": [
    "**Answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "936afe03-5f05-4575-ae2e-45f7c5195aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\" : \"094853d0aa3f\",\n",
      "  \"cluster_name\" : \"docker-cluster\",\n",
      "  \"cluster_uuid\" : \"zwGvJBupSkmkqXg5tsUFdw\",\n",
      "  \"version\" : {\n",
      "    \"number\" : \"8.17.6\",\n",
      "    \"build_flavor\" : \"default\",\n",
      "    \"build_type\" : \"docker\",\n",
      "    \"build_hash\" : \"dbcbbbd0bc4924cfeb28929dc05d82d662c527b7\",\n",
      "    \"build_date\" : \"2025-04-30T14:07:12.231372970Z\",\n",
      "    \"build_snapshot\" : false,\n",
      "    \"lucene_version\" : \"9.12.0\",\n",
      "    \"minimum_wire_compatibility_version\" : \"7.17.0\",\n",
      "    \"minimum_index_compatibility_version\" : \"7.0.0\"\n",
      "  },\n",
      "  \"tagline\" : \"You Know, for Search\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!curl elasticsearch:9200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1778fc1f-77ef-42c0-bbc6-80498d780533",
   "metadata": {},
   "source": [
    "**Getting the data**\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9809a47f-9770-4809-9e6b-7b1716a7b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890605d1-6415-4506-bffd-77d7f7f755d5",
   "metadata": {},
   "source": [
    "**Question 2: Indexing the data**\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b09ac9-8d21-4785-8c26-7d97488ee5f9",
   "metadata": {},
   "source": [
    "Create a new index (table) in ElasticSearch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a72f6bd0-ffe9-4fc3-bbab-b263498e7d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'course-questions'})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0,\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"},\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "es_client = Elasticsearch('http://elasticsearch:9200')\n",
    "if es_client.indices.get(index=index_name, ignore_unavailable=True):\n",
    "    es_client.indices.delete(index=index_name)\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f496a-dd05-443d-8b2d-f9305743f7cd",
   "metadata": {},
   "source": [
    "Start ingest all `documents` into ES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c24748e-8076-440f-9080-3f00e0e65d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in documents:\n",
    "    es_client.index(index=index_name, document=document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34046a5-9818-4a98-b024-1f54410ce268",
   "metadata": {},
   "source": [
    "Which function do you use for adding your data to elastic?\n",
    "* `insert`\n",
    "* `index`\n",
    "* `put`\n",
    "* `add`\n",
    "\n",
    "**Answer**: `index`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df43c58-38ff-4277-a3ad-229d68b02d83",
   "metadata": {},
   "source": [
    "**Question 3: Searching**\n",
    "___\n",
    "Now let's search in our index.\n",
    "\n",
    "We will execute a query \"How do execute a command on a Kubernetes pod?\".\n",
    "\n",
    "Use only `question` and `text` fields and give `question` a boost of 4, and use `\"type\": \"best_fields\"`.\n",
    "\n",
    "What's the score for the top ranking result?\n",
    "* 84.50\n",
    "* 64.50\n",
    "* 44.50\n",
    "* 24.50\n",
    "\n",
    "Look at the `_score` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6912aa84-a69d-4a0e-94a5-d69482a47482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.417362"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How do execute a command on a Kubernetes pod?\"\n",
    "search_query = {\n",
    "    \"size\": 5,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^4\", \"text\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es_client.search(index=index_name, body=search_query)\n",
    "response['hits']['hits'][0]['_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11b204c-18df-4758-8981-7696a3288d86",
   "metadata": {},
   "source": [
    "**Answer:** 44.50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72060451-a0d1-46f6-95b9-24de401b8eed",
   "metadata": {},
   "source": [
    "**Question 4: Filtering**\n",
    "___\n",
    "\n",
    "Now ask a different question: \"How do copy a file to a Docker container?\".\n",
    "\n",
    "This time we are only interested in questions from `machine-learning-zoomcamp`.\n",
    "\n",
    "Return 3 results. What's the 3rd question returned by the search engine?\n",
    "* How do I debug a docker container?\n",
    "* How do I copy files from a different folder into docker container’s working directory?\n",
    "* How do Lambda container images work?\n",
    "* How can I annotate a graph?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d56abc9c-cd3c-42b7-b876-95a7f5414f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do I copy files from a different folder into docker container’s working directory?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How do copy a file to a Docker container?\"\n",
    "course = \"machine-learning-zoomcamp\"\n",
    "search_query = {\n",
    "    \"size\": 3,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^4\", \"text\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": course\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "response = es_client.search(index=index_name, body=search_query)\n",
    "response['hits']['hits'][2]['_source']['question']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0afb69-4e22-4833-af7a-144eef4dfabf",
   "metadata": {},
   "source": [
    "**Answer:** `How do I copy files from a different folder into docker container’s working directory?`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee2c538-48cb-4456-b38c-6de18f6fed84",
   "metadata": {},
   "source": [
    "**Question 5:** Building a prompt\n",
    "___\n",
    "\n",
    "Now we're ready to build a prompt to send to an LLM.\n",
    "\n",
    "Take the records returned from Elasticsearch in Q4 and use this template to build the context. Separate context entries by two linebreaks (`\\n\\n`)\n",
    "\n",
    "```python\n",
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "```\n",
    "\n",
    "Now use the context you just created along with the \"How do copy a file to a Docker container?\" question to construct a prompt using the template below:\n",
    "\n",
    "```python\n",
    "prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "```\n",
    "\n",
    "What's the length of the resulting prompt? (use the len function)\n",
    "* 946\n",
    "* 1446\n",
    "* 1946\n",
    "* 2446"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1c2e954-8c0d-4cae-842b-7e40124acd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1446"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How do copy a file to a Docker container?\"\n",
    "course = \"machine-learning-zoomcamp\"\n",
    "search_query = {\n",
    "    \"size\": 3,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^4\", \"text\"],\n",
    "                    \"type\": \"best_fields\",\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": course\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "context_template = \"\"\"\n",
    "Q: {question}\n",
    "A: {text}\n",
    "\"\"\".strip()\n",
    "\n",
    "contexts = []\n",
    "response = es_client.search(index=index_name, body=search_query)\n",
    "for hit in response['hits']['hits']:\n",
    "    question = hit['_source']['question']\n",
    "    text = hit['_source']['text']\n",
    "    context = context_template.format(question=question, text=text)\n",
    "    contexts.append(context)\n",
    "\n",
    "context = '\\n\\n'.join(contexts)\n",
    "prompt = f\"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {query}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "len(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd39bbc-0b4f-45a4-954a-58ae35ef19ae",
   "metadata": {},
   "source": [
    "**Answer:** 1446"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea08395-dc34-4ea9-92f7-06b206669213",
   "metadata": {},
   "source": [
    "**Question 6:** Tokens\n",
    "___\n",
    "\n",
    "When we use the OpenAI Platform, we're charged by the number of tokens we send in our prompt and receive in the response.\n",
    "\n",
    "The OpenAI python package uses `tiktoken` for tokenization:\n",
    "\n",
    "```shell\n",
    "pip install tiktoken\n",
    "```\n",
    "\n",
    "Let's calculate the number of tokens in our query:\n",
    "\n",
    "```python\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "```\n",
    "\n",
    "Use the `encode` function. How many tokens does our prompt have?\n",
    "* 120\n",
    "* 220\n",
    "* 320\n",
    "* 420\n",
    "\n",
    "Note: to decode back a token into a word, you can use the `decode_single_token_bytes` function:\n",
    "```python\n",
    "encoding.decode_single_token_bytes(63842)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c543918c-4eef-486b-a95a-308fc9eef8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "320"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "encoding = tiktoken.encoding_for_model('gpt-4o')\n",
    "tokens = encoding.encode(text=prompt)\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cf9fc0-6d2b-46e8-a44b-c7712ddd88fd",
   "metadata": {},
   "source": [
    "**Answer:** `320`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
