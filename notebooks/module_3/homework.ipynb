{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f432ea73-d225-4347-9d61-361f928af79b",
   "metadata": {},
   "source": [
    "# Question 1. dlt Version\n",
    "___\n",
    "\n",
    "In this homework, we will load the data from our FAQ to Qdrant\n",
    "\n",
    "Let's install dlt with Qdrant support and Qdrant client:\n",
    "\n",
    "```shell\n",
    "pip install -q \"dlt[qdrant]\" \"qdrant-client[fastembed]\"\n",
    "```\n",
    "\n",
    "What's the version of dlt that you installed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efe370ec-0d3a-4fbd-8715-23eae50e60fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dlt==1.13.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dlt import version\n",
    "version.get_installed_requirement_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe34bac-3a4d-478c-a362-a122ba9b1d8e",
   "metadata": {},
   "source": [
    "**Answer:** `1.13.0`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474bc8a3-7f7b-445f-91cb-b191c98e8af2",
   "metadata": {},
   "source": [
    "## dlt Resourse\n",
    "___\n",
    "\n",
    "For reading the FAQ data, we have this helper function:\n",
    "\n",
    "```python\n",
    "def zoomcamp_data():\n",
    "    docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "    docs_response = requests.get(docs_url)\n",
    "    documents_raw = docs_response.json()\n",
    "\n",
    "    for course in documents_raw:\n",
    "        course_name = course['course']\n",
    "\n",
    "        for doc in course['documents']:\n",
    "            doc['course'] = course_name\n",
    "            yield doc\n",
    "```\n",
    "\n",
    "Annotate it with `@dlt.resource`. We will use it when creating a dlt pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36c9aeb-ad07-4fda-9939-1976a2e6519a",
   "metadata": {},
   "source": [
    "# Question 2. dlt pipeline\n",
    "___\n",
    "\n",
    "Now let's create a pipeline.\n",
    "\n",
    "We need to define a destination for that. Let's use the `qdrant` one:\n",
    "\n",
    "```python\n",
    "from dlt.destinations import qdrant\n",
    "\n",
    "qdrant_destination = qdrant(\n",
    "  qd_path=\"db.qdrant\", \n",
    ")\n",
    "```\n",
    "\n",
    "In this case, we tell dlt (and Qdrant) to create a folder with our data, and the name for it will be `db.qdrant`.\n",
    "\n",
    "Let's run it:\n",
    "\n",
    "```python\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"zoomcamp_pipeline\",\n",
    "    destination=qdrant_destination,\n",
    "    dataset_name=\"zoomcamp_tagged_data\"\n",
    "\n",
    ")\n",
    "load_info = pipeline.run(zoomcamp_data())\n",
    "print(pipeline.last_trace)\n",
    "```\n",
    "\n",
    "How many rows were inserted into the zoomcamp_data collection?\n",
    "\n",
    "Look for `\"Normalized data for the following tables:\"` in the trace output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e88df9cf-fc7d-41dd-b578-8ea64c0cefb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run started at 2025-07-11 01:48:37.225111+00:00 and COMPLETED in 8.89 seconds with 4 steps.\n",
      "Step extract COMPLETED in 1.02 seconds.\n",
      "\n",
      "Load package 1752198518.465681 is EXTRACTED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step normalize COMPLETED in 0.06 seconds.\n",
      "Normalized data for the following tables:\n",
      "- zoomcamp_data: 948 row(s)\n",
      "- _dlt_pipeline_state: 1 row(s)\n",
      "\n",
      "Load package 1752198518.465681 is NORMALIZED and NOT YET LOADED to the destination and contains no failed jobs\n",
      "\n",
      "Step load COMPLETED in 6.57 seconds.\n",
      "Pipeline zoomcamp_pipeline load step completed in 6.56 seconds\n",
      "1 load package(s) were loaded to destination qdrant and into dataset zoomcamp_tagged_data\n",
      "The qdrant destination used /home/jovyan/work/module_3/db.qdrant location to store data\n",
      "Load package 1752198518.465681 is LOADED and contains no failed jobs\n",
      "\n",
      "Step run COMPLETED in 8.88 seconds.\n",
      "Pipeline zoomcamp_pipeline load step completed in 6.56 seconds\n",
      "1 load package(s) were loaded to destination qdrant and into dataset zoomcamp_tagged_data\n",
      "The qdrant destination used /home/jovyan/work/module_3/db.qdrant location to store data\n",
      "Load package 1752198518.465681 is LOADED and contains no failed jobs\n"
     ]
    }
   ],
   "source": [
    "import dlt\n",
    "import requests\n",
    "from dlt.destinations import qdrant\n",
    "\n",
    "\n",
    "@dlt.resource\n",
    "def zoomcamp_data():\n",
    "    docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "    docs_response = requests.get(docs_url)\n",
    "    documents_raw = docs_response.json()\n",
    "\n",
    "    for course in documents_raw:\n",
    "        course_name = course['course']\n",
    "\n",
    "        for doc in course['documents']:\n",
    "            doc['course'] = course_name\n",
    "            yield doc\n",
    "\n",
    "qdrant_destination = qdrant(qd_path=\"db.qdrant\")\n",
    "pipeline = dlt.pipeline(\n",
    "    pipeline_name=\"zoomcamp_pipeline\",\n",
    "    destination=qdrant_destination,\n",
    "    dataset_name=\"zoomcamp_tagged_data\"\n",
    "\n",
    ")\n",
    "load_info = pipeline.run(zoomcamp_data())\n",
    "print(pipeline.last_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8351159-15b0-4e4b-b6b7-142fc392d9c6",
   "metadata": {},
   "source": [
    "**Answer:** `948`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fe53b2-3d2e-47a9-b64f-903c531d9135",
   "metadata": {},
   "source": [
    "# Question 3. Embeddings\n",
    "___\n",
    "\n",
    "When inserting the data, an embedding model was used. Which one?\n",
    "\n",
    "You can find this out by inspecting the `meta.json` file created in the target folder. During the data insertion process, a folder named db.qdrant will be created, and the meta.json file will be located inside this folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a98747-41f0-46fd-83c8-85e0d6124768",
   "metadata": {},
   "source": [
    "**Answer**: `bge-small-en`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f94e8b-4b13-4130-bce0-e8a003193357",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
